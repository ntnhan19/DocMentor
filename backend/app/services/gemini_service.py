import google.generativeai as genai
from typing import List, Dict, Any
import logging
from ..config import settings

logger = logging.getLogger(__name__)

class GeminiService:
    """
    Service for interacting with Google Gemini AI
    Features:
    - Text generation (for RAG answers)
    - Embeddings (if needed later)
    - Structured output
    """
    
    def __init__(self):
        # Configure Gemini
        genai.configure(api_key=settings.GEMINI_API_KEY)
        
        # Initialize models
        self.chat_model = genai.GenerativeModel('gemini-2.5-flash')
        
        logger.info("‚úÖ Gemini service initialized")
    
    async def generate_answer(
        self, 
        query: str, 
        context: str,
        system_instruction: str = None
    ) -> str:
        """
        Generate answer using Gemini based on context
        
        Args:
            query: User's question
            context: Retrieved context from documents
            system_instruction: Optional system instructions
        
        Returns:
            Generated answer
        """
        try:
            # Build prompt
            if system_instruction:
                prompt = f"""{system_instruction}

CONTEXT (Tr√≠ch t·ª´ t√†i li·ªáu):
{context}

QUESTION:
{query}

ANSWER (Tr·∫£ l·ªùi b·∫±ng ti·∫øng Vi·ªát, d·ª±a tr√™n context tr√™n):"""
            else:
                prompt = f"""B·∫°n l√† m·ªôt tr·ª£ gi·∫£ng th√¥ng minh. Nhi·ªám v·ª• c·ªßa b·∫°n l√† tr·∫£ l·ªùi c√¢u h·ªèi c·ªßa sinh vi√™n d·ª±a HO√ÄN TO√ÄN tr√™n n·ªôi dung ƒë∆∞·ª£c cung c·∫•p.

QUY T·∫ÆC:
1. Ch·ªâ tr·∫£ l·ªùi d·ª±a tr√™n CONTEXT b√™n d∆∞·ªõi
2. Tr·∫£ l·ªùi b·∫±ng ti·∫øng Vi·ªát r√µ r√†ng, d·ªÖ hi·ªÉu
3. Tr√≠ch d·∫´n ngu·ªìn khi c·∫ßn: [Ngu·ªìn: t√™n t√†i li·ªáu]
4. N·∫øu kh√¥ng t√¨m th·∫•y th√¥ng tin, n√≥i r√µ "T√¥i kh√¥ng t√¨m th·∫•y th√¥ng tin v·ªÅ..."
5. KH√îNG b·ªãa ƒë·∫∑t th√¥ng tin kh√¥ng c√≥ trong context

CONTEXT (Tr√≠ch t·ª´ t√†i li·ªáu):
{context}

QUESTION:
{query}

ANSWER (Tr·∫£ l·ªùi ng·∫Øn g·ªçn, s√∫c t√≠ch):"""

            # Generate response
            logger.info("ü§ñ Generating answer with Gemini...")
            response = self.chat_model.generate_content(prompt)
            
            answer = response.text.strip()
            logger.info(f"‚úÖ Answer generated: {len(answer)} characters")
            
            return answer
            
        except Exception as e:
            logger.error(f"‚ùå Error generating answer: {str(e)}")
            raise
    
    async def generate_summary(self, text: str, length: str = "medium") -> str:
        """
        Generate summary of document
        
        Args:
            text: Document text
            length: "short", "medium", or "long"
        
        Returns:
            Summary text
        """
        try:
            length_instructions = {
                "short": "5 c√¢u ng·∫Øn g·ªçn",
                "medium": "1-2 ƒëo·∫°n vƒÉn",
                "long": "chi ti·∫øt theo t·ª´ng ph·∫ßn"
            }
            
            prompt = f"""T√≥m t·∫Øt n·ªôi dung sau b·∫±ng ti·∫øng Vi·ªát, ƒë·ªô d√†i: {length_instructions.get(length, "1-2 ƒëo·∫°n vƒÉn")}

N·ªòI DUNG:
{text[:10000]}  # Limit to first 10K chars

T√ìM T·∫ÆT:"""

            response = self.chat_model.generate_content(prompt)
            return response.text.strip()
            
        except Exception as e:
            logger.error(f"‚ùå Error generating summary: {str(e)}")
            raise
    
    async def extract_key_concepts(self, text: str) -> List[str]:
        """
        Extract key concepts from text
        
        Args:
            text: Document text
            
        Returns:
            List of key concepts
        """
        try:
            prompt = f"""Tr√≠ch xu·∫•t c√°c kh√°i ni·ªám ch√≠nh t·ª´ vƒÉn b·∫£n sau. Ch·ªâ li·ªát k√™ c√°c thu·∫≠t ng·ªØ quan tr·ªçng, m·ªói thu·∫≠t ng·ªØ tr√™n m·ªôt d√≤ng.

VƒÇN B·∫¢N:
{text[:8000]}

KH√ÅI NI·ªÜM CH√çNH (m·ªói d√≤ng m·ªôt kh√°i ni·ªám):"""

            response = self.chat_model.generate_content(prompt)
            concepts = [line.strip() for line in response.text.split('\n') if line.strip()]
            
            return concepts[:15]  # Return top 15
            
        except Exception as e:
            logger.error(f"‚ùå Error extracting concepts: {str(e)}")
            raise
    
    async def generate_quiz(
        self, 
        text: str, 
        num_questions: int = 5,
        difficulty: str = "medium"
    ) -> List[Dict[str, Any]]:
        """
        Generate quiz questions from text
        
        Args:
            text: Document text
            num_questions: Number of questions to generate
            difficulty: "easy", "medium", or "hard"
            
        Returns:
            List of quiz questions with options and answers
        """
        try:
            prompt = f"""T·∫°o {num_questions} c√¢u h·ªèi tr·∫Øc nghi·ªám (multiple choice) t·ª´ n·ªôi dung sau, ƒë·ªô kh√≥: {difficulty}.

Y√äU C·∫¶U:
- M·ªói c√¢u h·ªèi c√≥ 4 ƒë√°p √°n (A, B, C, D)
- Ch·ªâ c√≥ 1 ƒë√°p √°n ƒë√∫ng
- Format JSON nh∆∞ sau:
[
  {{
    "question": "C√¢u h·ªèi ·ªü ƒë√¢y?",
    "options": ["A. ƒê√°p √°n 1", "B. ƒê√°p √°n 2", "C. ƒê√°p √°n 3", "D. ƒê√°p √°n 4"],
    "correct": "A",
    "explanation": "Gi·∫£i th√≠ch ng·∫Øn g·ªçn"
  }}
]

N·ªòI DUNG:
{text[:8000]}

JSON OUTPUT:"""

            response = self.chat_model.generate_content(prompt)
            
            # Parse JSON from response (basic parsing)
            import json
            import re
            
            # Extract JSON from markdown code blocks if present
            json_text = response.text.strip()
            if "```json" in json_text:
                json_text = re.search(r'```json\n(.*?)\n```', json_text, re.DOTALL).group(1)
            elif "```" in json_text:
                json_text = re.search(r'```\n(.*?)\n```', json_text, re.DOTALL).group(1)
            
            questions = json.loads(json_text)
            return questions
            
        except Exception as e:
            logger.error(f"‚ùå Error generating quiz: {str(e)}")
            raise